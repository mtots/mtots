import sys

final c00 = sys.getMallocCount()
final r1 = range(5, 15)
final c01 = sys.getMallocCount()
final r2 = range(5000000000, 5000000000 + 10) # 5 billion - fits in double, but not in i32
final c02 = sys.getMallocCount()

print("mallocCount (r1) = %r" % [c01 - c00])
print("mallocCount (r2) = %r" % [c02 - c01])
print(List(r1))
print(List(r2))

final c10 = sys.getMallocCount()
var total1 = 0
for value in range(5, 15):
  total1 = total1 + value
final c11 = sys.getMallocCount()
var total2 = 0
for value in range(5000000000, 5000000000 + 10):
  total2 = total2 + value
final c12 = sys.getMallocCount()

print("mallocCount (total1) = %r" % [c11 - c10])
print("mallocCount (total2) = %r" % [c12 - c11])
print("total1 = %r" % [total1])
print("total2 = %r" % [total2])

final c20 = sys.getMallocCount()
final sum1 = sum(range(5, 15))
final c21 = sys.getMallocCount()
final sum2 = sum(range(5000000000, 5000000000 + 10))
final c22 = sys.getMallocCount()

print("mallocCount (sum1) = %r" % [c21 - c20])
print("mallocCount (sum2) = %r" % [c22 - c21])
print("sum1 = %r" % [sum1])
print("sum2 = %r" % [sum2])

final c30 = sys.getMallocCount()
final lr1 = range(5, -5, -2)
final c31 = sys.getMallocCount()
final lr2 = range(5000000000 + 10, 5000000000, -2)
final c32 = sys.getMallocCount()

print("mallocCount (lr1) = %r" % [c31 - c30])
print("mallocCount (lr2) = %r" % [c32 - c31])
print("lr1 = %r" % [List(lr1)])
print("lr2 = %r" % [List(lr2)])

final c40 = sys.getMallocCount()
var t1 = 0
for value in range(5, -5, -2):
  t1 = t1 + value
final c41 = sys.getMallocCount()
var t2 = 0
for value in range(5000000000 + 10, 5000000000, -2):
  t2 = t2 + value
final c42 = sys.getMallocCount()

print("mallocCount (t1) = %r" % [c41 - c40])
print("mallocCount (t2) = %r" % [c42 - c41])
print("t1 = %r" % [t1])
print("t2 = %r" % [t2])

print(range(5, 10))
print(range(5, -5, -2))
print(range(5000000000 + 10, 5000000000, -2))
